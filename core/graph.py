"""
LangGraphæµç¨‹ç¼–æ’æ¨¡å—
å®ç°TDRèšç±»çš„å®Œæ•´å·¥ä½œæµï¼šclusterer -> reviewer -> dispatcher
"""
from typing import List, Dict, Any
from collections import deque
from langgraph.graph import StateGraph, END

from .state import GraphState, Query, Task, Cluster
from .tools import (
    create_new_category_tool, 
    assign_to_existing_tool, 
    subdivide_task_tool,
    parse_cluster_ids,
    get_clusters_by_ids
)
from .prompts import (
    create_cluster_display_dict,
    create_category_display_dict
)
from services.embedding_service import EmbeddingService
from services.clustering_service import ClusteringService


class TDRClusterGraph:
    """TDRèšç±»ä¸»å·¥ä½œæµ"""
    
    def __init__(self, llm_service):
        self.llm_service = llm_service
        self.embedding_service = EmbeddingService()
        self.clustering_service = ClusteringService()
        
        # æ„å»ºLangGraphå·¥ä½œæµ
        self.graph = self._build_graph()
    
    def _build_graph(self) -> StateGraph:
        """æ„å»ºLangGraphå·¥ä½œæµ"""
        workflow = StateGraph(GraphState)
        
        # æ·»åŠ èŠ‚ç‚¹
        workflow.add_node("clusterer", self.clusterer_node)
        workflow.add_node("reviewer", self.reviewer_node)
        workflow.add_node("dispatcher", self.dispatcher_node)
        
        # è®¾ç½®æµç¨‹
        workflow.set_entry_point("clusterer")
        workflow.add_edge("clusterer", "reviewer")
        workflow.add_edge("reviewer", "dispatcher")
        
        # æ¡ä»¶å¾ªç¯
        workflow.add_conditional_edges(
            "dispatcher",
            self._should_continue,
            {
                "continue": "clusterer",
                "end": END
            }
        )
        
        return workflow.compile()
    
    def clusterer_node(self, state: GraphState) -> Dict[str, Any]:
        """
        èšç±»èŠ‚ç‚¹ï¼šä»é˜Ÿåˆ—å–ä»»åŠ¡ï¼Œæ‰§è¡ŒK-Meansèšç±»
        """
        print("ğŸ”µ è¿›å…¥clustererèŠ‚ç‚¹")
        
        tasks = state["tasks"]
        if not tasks:
            print("   é˜Ÿåˆ—ä¸ºç©ºï¼Œè·³è¿‡èšç±»")
            return {"clusters_list": []}
        
        # ä»é˜Ÿåˆ—å–å‡ºä»»åŠ¡
        current_task = tasks.popleft()
        queries_to_cluster = current_task.queries
        k_value = current_task.k_value
        
        print(f"   å¤„ç†ä»»åŠ¡: {len(queries_to_cluster)} ä¸ªæŸ¥è¯¢ -> {k_value} ä¸ªclusters")
        
        # æ‰§è¡Œèšç±»
        clusters = self.clustering_service.perform_clustering(queries_to_cluster, k_value)
        
        print(f"   èšç±»å®Œæˆ: ç”Ÿæˆ {len(clusters)} ä¸ªæœ‰æ•ˆclusters")
        
        return {
            "tasks": tasks,
            "clusters_list": clusters
        }
    
    def reviewer_node(self, state: GraphState) -> Dict[str, Any]:
        """
        è¯„å®¡èŠ‚ç‚¹ï¼šè°ƒç”¨LLMå¯¹clustersè¿›è¡Œå†³ç­–
        """
        print("ğŸŸ¡ è¿›å…¥reviewerèŠ‚ç‚¹")
        
        clusters_to_review = state.get("clusters_list", [])
        categories = state.get("categories", {})
        
        if not clusters_to_review:
            print("   æ— clusterséœ€è¦è¯„å®¡")
            return {"clusters_list": []}
        
        print(f"   è¯„å®¡ {len(clusters_to_review)} ä¸ªclusters")
        
        # å‡†å¤‡LLMè¾“å…¥æ•°æ®
        finalized_categories = [
            create_category_display_dict(cat) for cat in categories.values()
        ]
        clusters_for_review = [
            create_cluster_display_dict(cluster) for cluster in clusters_to_review
        ]
        
        # ä½¿ç”¨ç¼“å­˜çš„æ€»æŸ¥è¯¢æ•°ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
        total_queries = state["total_queries"]
        
        # ä½¿ç”¨LLMæœåŠ¡çš„é«˜çº§æ–¹æ³•è¿›è¡Œclusteråˆ†æï¼ˆåŒ…å«é‡è¯•æœºåˆ¶ï¼‰
        try:
            validation_result = self.llm_service.analyze_clusters_with_retry(
                finalized_categories, 
                clusters_for_review,
                state.get("dataset_name")
            )
            
            # å°†å†³ç­–é™„åŠ åˆ°å¯¹åº”çš„clusters
            decisions = validation_result['decisions']
            print(f"ğŸ” è°ƒè¯•ï¼šå‡†å¤‡é™„åŠ  {len(decisions)} ä¸ªå†³ç­–åˆ° {len(clusters_to_review)} ä¸ªclusters")
            for i, decision in enumerate(decisions):
                print(f"   å†³ç­– {i+1}: ID={decision.get('id')}, Action={decision.get('action')}")
            self._attach_decisions_to_clusters(clusters_to_review, decisions)
            
        except Exception as e:
            print(f"âŒ LLMåˆ†æå¤±è´¥: {str(e)}")
            raise
        
        return {
            "tasks": state.get("tasks", deque()),
            "categories": state.get("categories", {}),
            "clusters_list": clusters_to_review
        }
    
    def dispatcher_node(self, state: GraphState) -> Dict[str, Any]:
        """
        åˆ†å‘èŠ‚ç‚¹ï¼šæ ¹æ®LLMå†³ç­–æ‰§è¡Œç›¸åº”æ“ä½œ
        """
        print("ğŸŸ¢ è¿›å…¥dispatcherèŠ‚ç‚¹")
        
        clusters_to_process = state.get("clusters_list", [])
        
        if not clusters_to_process:
            print("   æ— clusterséœ€è¦å¤„ç†")
            return {
                "tasks": state.get("tasks", deque()),
                "categories": state.get("categories", {}),
                "clusters_list": []
            }
        
        print(f"   å¤„ç† {len(clusters_to_process)} ä¸ªclustersçš„å†³ç­–")
        
        # ä½¿ç”¨ç¼“å­˜çš„ç»Ÿè®¡ä¿¡æ¯ï¼ˆé¿å…é‡å¤è®¡ç®—ï¼‰
        total_queries = state["total_queries"]
        min_cluster_size = state["min_cluster_size"]
        
        for cluster in clusters_to_process:
            decision = cluster.judge
            if not decision:
                print(f"âš ï¸ Cluster {cluster.id} æ— å†³ç­–ï¼Œè·³è¿‡")
                continue
            
            action = decision.get("action", "").lower()
            print(f"   å¤„ç† {cluster.id}: {action}")
            
            try:
                if action == "create":
                    self._handle_create_action(state, cluster, decision)
                elif action == "assign":
                    self._handle_assign_action(state, cluster, decision)
                elif action == "subdivide":
                    self._handle_subdivide_action(state, cluster, decision, min_cluster_size)
                else:
                    print(f"âŒ æœªçŸ¥åŠ¨ä½œ: {action}")
            except Exception as e:
                print(f"âŒ å¤„ç†cluster {cluster.id} æ—¶å‡ºé”™: {str(e)}")
        
        return {
            "tasks": state.get("tasks", deque()),
            "categories": state.get("categories", {}),
            "clusters_list": []  # æ¸…ç©ºå·²å¤„ç†çš„clusters
        }
    
    
    def _attach_decisions_to_clusters(self, clusters: List[Cluster], decisions: List[Dict[str, Any]]):
        """å°†LLMå†³ç­–é™„åŠ åˆ°å¯¹åº”çš„clusters"""
        cluster_dict = {cluster.id: cluster for cluster in clusters}
        print(f"ğŸ” è°ƒè¯•ï¼šå¯ç”¨cluster IDs: {list(cluster_dict.keys())}")
        
        attached_count = 0
        for decision in decisions:
            cluster_ids = parse_cluster_ids(decision.get("id", ""))
            print(f"ğŸ” è°ƒè¯•ï¼šè§£æå†³ç­–ID '{decision.get('id')}' -> {cluster_ids}")
            
            for cluster_id in cluster_ids:
                if cluster_id in cluster_dict:
                    cluster_dict[cluster_id].judge = decision
                    attached_count += 1
                    print(f"   âœ“ é™„åŠ å†³ç­–åˆ° {cluster_id}: {decision.get('action')}")
                else:
                    print(f"   âŒ æ‰¾ä¸åˆ°cluster: {cluster_id}")
        
        print(f"ğŸ” è°ƒè¯•ï¼šæ€»å…±é™„åŠ äº† {attached_count} ä¸ªå†³ç­–")
    
    def _handle_create_action(self, state: GraphState, cluster: Cluster, decision: Dict[str, Any]):
        """å¤„ç†createåŠ¨ä½œï¼ˆæ”¯æŒå¤šclusteråˆå¹¶ï¼‰"""
        cluster_ids = parse_cluster_ids(decision.get("id", ""))
        all_clusters = get_clusters_by_ids(state.get("clusters_list", []), cluster_ids)
        
        if not all_clusters:
            print(f"âš ï¸ æ‰¾ä¸åˆ°clusters: {cluster_ids}")
            return
        
        description = decision.get("description", "æ–°åˆ›å»ºçš„ç±»åˆ«")
        create_new_category_tool(state, all_clusters, description)
    
    def _handle_assign_action(self, state: GraphState, cluster: Cluster, decision: Dict[str, Any]):
        """å¤„ç†assignåŠ¨ä½œï¼ˆæ”¯æŒå¤šclusteråˆå¹¶assignï¼‰"""
        cluster_ids = parse_cluster_ids(decision.get("id", ""))
        all_clusters = get_clusters_by_ids(state.get("clusters_list", []), cluster_ids)
        
        if not all_clusters:
            print(f"âš ï¸ æ‰¾ä¸åˆ°clusters: {cluster_ids}")
            return
        
        target_id = decision.get("target_id")
        description_update = decision.get("description_update", "no_update")
        
        if not target_id:
            print(f"âŒ assignåŠ¨ä½œç¼ºå°‘target_id")
            return
        
        # åˆå¹¶æ‰€æœ‰clustersåˆ°ç›®æ ‡category
        for cluster_item in all_clusters:
            assign_to_existing_tool(state, cluster_item, target_id, "no_update")
        
        # æœ€åç»Ÿä¸€æ›´æ–°description
        if description_update != "no_update" and target_id in state['categories']:
            state['categories'][target_id].description = description_update
            print(f"å·²æ›´æ–°ç±»åˆ« {target_id} çš„æè¿°")
    
    def _handle_subdivide_action(self, state: GraphState, cluster: Cluster, 
                                decision: Dict[str, Any], min_cluster_size: int):
        """å¤„ç†subdivideåŠ¨ä½œ"""
        k_value = decision.get("k_value")
        if not k_value:
            print(f"âŒ subdivideåŠ¨ä½œç¼ºå°‘k_value")
            return
        subdivide_task_tool(state, cluster, k_value, min_cluster_size)
    
    
    def _should_continue(self, state: GraphState) -> str:
        """åˆ¤æ–­æ˜¯å¦ç»§ç»­å¾ªç¯"""
        tasks = state.get("tasks", deque())
        if len(tasks) > 0:
            print(f"   é˜Ÿåˆ—è¿˜æœ‰ {len(tasks)} ä¸ªä»»åŠ¡ï¼Œç»§ç»­å¾ªç¯")
            return "continue"
        else:
            print("   é˜Ÿåˆ—ä¸ºç©ºï¼Œç»“æŸæµç¨‹")
            return "end"
    
    def run(self, initial_queries: List[Query], initial_k: int = 10, dataset_name: str = None) -> Dict[str, Any]:
        """
        è¿è¡Œå®Œæ•´çš„TDRèšç±»æµç¨‹
        
        Args:
            initial_queries: åˆå§‹æŸ¥è¯¢åˆ—è¡¨
            initial_k: åˆå§‹èšç±»æ•°
            dataset_name: æ•°æ®é›†åç§°ï¼Œç”¨äºè·å–ç‰¹å®šçš„high-levelç›®æ ‡
            
        Returns:
            Dict[str, Any]: æœ€ç»ˆçŠ¶æ€ï¼ŒåŒ…å«æ‰€æœ‰categories
        """
        print(f"ğŸš€ å¼€å§‹TDRèšç±»æµç¨‹")
        print(f"   åˆå§‹æ•°æ®: {len(initial_queries)} ä¸ªæŸ¥è¯¢")
        print(f"   åˆå§‹Kå€¼: {initial_k}")
        
        # è®¡ç®—å…¨å±€ç»Ÿè®¡ä¿¡æ¯ï¼ˆä¸€æ¬¡æ€§è®¡ç®—ï¼Œé¿å…é‡å¤ï¼‰
        total_queries = len(initial_queries)
        min_cluster_size = self.clustering_service.calculate_min_cluster_size(total_queries)
        
        print(f"ğŸ“Š åˆå§‹ç»Ÿè®¡ä¿¡æ¯:")
        print(f"   æ€»æŸ¥è¯¢æ•°: {total_queries}")
        print(f"   æœ€å°ç°‡å¤§å°: {min_cluster_size}")
        
        # æ„å»ºåˆå§‹çŠ¶æ€
        initial_task = Task(queries=initial_queries, k_value=initial_k)
        initial_state: GraphState = {
            "tasks": deque([initial_task]),
            "categories": {},
            "clusters_list": [],
            "dataset_name": dataset_name,
            "total_queries": total_queries,
            "min_cluster_size": min_cluster_size
        }
        
        # æ‰§è¡Œå›¾å·¥ä½œæµ
        from config.config_loader import CONFIG
        recursion_limit = CONFIG.get('system', {}).get('recursion_limit', 100)
        
        final_state = self.graph.invoke(initial_state, config={"recursion_limit": recursion_limit})
        
        print("âœ… TDRèšç±»æµç¨‹å®Œæˆ")
        print(f"   æœ€ç»ˆç±»åˆ«æ•°: {len(final_state.get('categories', {}))}")
        
        return final_state