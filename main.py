#!/usr/bin/env python3
"""
TDRClusterä¸»å¯åŠ¨æ–‡ä»¶ - ç®€åŒ–ç‰ˆæœ¬
"""
import json
from pathlib import Path
from datetime import datetime

# é…ç½®ç®¡ç†å’Œæ ¸å¿ƒç»„ä»¶  
from config.config_loader import CONFIG
from core.graph import TDRClusterGraph
from services.dataset_manager import DatasetManager
from services.llm_service import LLMService


def load_params() -> dict:
    """åŠ è½½è¿è¡Œå‚æ•°"""
    runtime_config = CONFIG.get('runtime', {})
    clustering_config = CONFIG.get('clustering', {})
    
    return {
        'dataset': runtime_config.get('dataset', 'banking77'),
        'initial_k': clustering_config.get('initial_k', 10),
        'sample_size': runtime_config.get('sample_size', None),
        'output_dir': 'output'  # ç¡¬ç¼–ç è¾“å‡ºè·¯å¾„
    }




def save_results(final_state: dict, output_dir: str, dataset_name: str) -> tuple[Path, Path]:
    """ä¿å­˜èšç±»ç»“æœ"""
    output_path = Path(output_dir)
    output_path.mkdir(exist_ok=True)
    
    timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    # ä¿å­˜è¯¦ç»†ç»“æœåˆ°CSV
    print(f"ğŸ’¾ ä¿å­˜ç»“æœåˆ°: {output_dir}/")
    
    import pandas as pd
    
    results_data = []
    categories = final_state.get('categories', {})
    
    for cat_id, category in categories.items():
        for query in category.queries:
            results_data.append({
                'query_id': query.id,
                'query_content': query.content,
                'category_id': category.id,
                'category_description': category.description,
                'dataset': dataset_name,
                'timestamp': timestamp
            })
    
    csv_path = None
    if results_data:
        results_df = pd.DataFrame(results_data)
        csv_path = output_path / f"{dataset_name}_clustering_{timestamp}.csv"
        results_df.to_csv(csv_path, index=False)
        print(f"   âœ“ è¯¦ç»†ç»“æœ: {csv_path}")
    
    # ä¿å­˜æ‘˜è¦åˆ°JSON
    summary_data = {
        'dataset': dataset_name,
        'timestamp': timestamp,
        'total_queries': sum(len(cat.queries) for cat in categories.values()),
        'total_categories': len(categories),
        'categories': {}
    }
    
    for cat_id, category in categories.items():
        summary_data['categories'][cat_id] = {
            'description': category.description,
            'query_count': len(category.queries),
            'samples': category.samples[:5]
        }
    
    json_path = output_path / f"{dataset_name}_summary_{timestamp}.json"
    with open(json_path, 'w', encoding='utf-8') as f:
        json.dump(summary_data, f, ensure_ascii=False, indent=2)
    print(f"   âœ“ æ‘˜è¦æŠ¥å‘Š: {json_path}")
    
    return csv_path, json_path


def print_results_summary(final_state: dict, dataset_name: str):
    """æ‰“å°ç»“æœæ‘˜è¦"""
    categories = final_state.get('categories', {})
    tasks_remaining = final_state.get('tasks', [])
    
    print("\n" + "="*70)
    print(f"ğŸ“Š TDRèšç±»ç»“æœæ‘˜è¦ - {dataset_name}")
    print("="*70)
    
    print(f"æœ€ç»ˆç±»åˆ«æ•°: {len(categories)}")
    print(f"å‰©ä½™ä»»åŠ¡æ•°: {len(tasks_remaining)}")
    
    total_queries = sum(len(cat.queries) for cat in categories.values())
    print(f"æ€»åˆ†ç±»æŸ¥è¯¢æ•°: {total_queries}")
    
    if categories:
        print(f"\nğŸ“ ç±»åˆ«è¯¦æƒ…:")
        for i, (cat_id, category) in enumerate(categories.items(), 1):
            query_count = len(category.queries)
            print(f"\n{i}. {cat_id} ({query_count} ä¸ªæŸ¥è¯¢)")
            print(f"   æè¿°: {category.description}")
            
            if category.samples:
                print("   æ ·æœ¬:")
                for j, sample in enumerate(category.samples[:3]):
                    print(f"     {j+1}. {sample[:60]}...")
    
    print("="*70)


def main():
    """ä¸»å‡½æ•°"""
    print("ğŸš€ TDRCluster - LLMé©±åŠ¨çš„åŠ¨æ€æ„å›¾èšç±»ç³»ç»Ÿ\n")
    
    # åˆå§‹åŒ–æœåŠ¡
    print("âš™ï¸ åˆå§‹åŒ–LLMæœåŠ¡...")
    llm_service = LLMService(CONFIG.get('llm', {}))
    
    print("âœ… LLMæœåŠ¡åˆå§‹åŒ–å®Œæˆ\n")
    
    # åŠ è½½è¿è¡Œå‚æ•°
    params = load_params()
    
    # æ˜¾ç¤ºè¿è¡Œå‚æ•°
    print("âš™ï¸ è¿è¡Œå‚æ•°:")
    print(f"   æ•°æ®é›†: {params['dataset']}")
    print(f"   åˆå§‹Kå€¼: {params['initial_k']}")
    if params['sample_size']:
        print(f"   é‡‡æ ·å¤§å°: {params['sample_size']}")
    print(f"   è¾“å‡ºç›®å½•: {params['output_dir']}")
    print()
    
    # åˆå§‹åŒ–æ•°æ®é›†ç®¡ç†å™¨
    print("ğŸ” åˆå§‹åŒ–æ•°æ®é›†ç®¡ç†å™¨...")
    dataset_manager = DatasetManager()
    
    # åŠ è½½æ•°æ®é›†
    try:
        queries = dataset_manager.load_dataset_as_queries(
            params['dataset'], 
            params['sample_size']
        )
        
        if not queries:
            print("âŒ æ²¡æœ‰åŠ è½½åˆ°ä»»ä½•æŸ¥è¯¢æ•°æ®")
            return
        
    except Exception as e:
        print(f"âŒ æ•°æ®é›†åŠ è½½å¤±è´¥: {e}")
        return
    
    # åˆå§‹åŒ–TDRç³»ç»Ÿ
    print("ğŸ”§ åˆå§‹åŒ–TDRèšç±»ç³»ç»Ÿ...")
    try:
        tdr_graph = TDRClusterGraph(llm_service)
        print("   âœ“ TDRç³»ç»Ÿåˆå§‹åŒ–æˆåŠŸ")
    except Exception as e:
        print(f"âŒ ç³»ç»Ÿåˆå§‹åŒ–å¤±è´¥: {e}")
        return
    
    # è¿è¡Œèšç±»æµç¨‹
    print(f"\nâš¡ å¼€å§‹TDRèšç±»æµç¨‹...")
    print("   è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
    print("="*70)
    
    try:
        final_state = tdr_graph.run(
            initial_queries=queries,
            initial_k=params['initial_k'],
            dataset_name=params['dataset']
        )
        print("="*70)
        print("âœ… TDRèšç±»æµç¨‹å®Œæˆ!")
        
    except Exception as e:
        print(f"âŒ èšç±»æµç¨‹å¤±è´¥: {e}")
        return
    
    # æ˜¾ç¤ºç»“æœæ‘˜è¦
    print_results_summary(final_state, params['dataset'])
    
    # ä¿å­˜ç»“æœ
    try:
        csv_path, json_path = save_results(
            final_state, 
            params['output_dir'], 
            params['dataset']
        )
        
        print(f"\nğŸ’¾ ç»“æœå·²ä¿å­˜:")
        if csv_path:
            print(f"   è¯¦ç»†æ•°æ®: {csv_path}")
        print(f"   æ‘˜è¦æŠ¥å‘Š: {json_path}")
        
    except Exception as e:
        print(f"âŒ ä¿å­˜ç»“æœå¤±è´¥: {e}")
    
    print(f"\nğŸ‰ TDRClusterèšç±»ä»»åŠ¡å®Œæˆ!")


if __name__ == "__main__":
    main()